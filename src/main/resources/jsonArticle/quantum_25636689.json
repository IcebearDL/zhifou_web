{
    "title": "量子物理推动机器学习",
    "userNickname": "尹璋琦",
    "userDescription": "物理学 话题的优秀回答者",
    "userImageUrl": "https://pic1.zhimg.com/v2-bf429a939cce09d19ab6e70b3f29667c_is.jpg",
    "answerStar": 95,
    "commentNumber": 6,
    "answerExtraction": " 作者：Maria Schuld，南非夸祖鲁-纳塔尔大学博士生，研究机器学习与量子信息 翻译：郜勋，尹璋琦，清华大学交叉信息研究院 翻译自： A quantum boost for machine learning 删减版在《物理》杂志上在线出版： 量子物理推动机器学习 Maria Schuld 讲述了研究人员正如何通",
    "answerLength": 4681,
    "globalKeyword": [
        "量子",
        "机器",
        "计算机",
        "数据",
        "问题"
    ],
    "answerDescription": "<p>\n 作者：Maria Schuld，南非夸祖鲁-纳塔尔大学博士生，研究机器学习与量子信息\n</p>\n<p>\n 翻译：郜勋，尹璋琦，清华大学交叉信息研究院\n</p>\n<p>\n 翻译自：\n <a class=' wrap external' href='https://link.zhihu.com/?target=http%3A//live.iop-pp01.agh.sleek.net/2017/02/26/a-quantum-boost-for-machine-learning/' rel='nofollow noreferrer' target='_blank'>\n  A quantum boost for machine learning\n </a>\n</p>\n<p>\n 删减版在《物理》杂志上在线出版：\n <a class=' wrap external' href='https://link.zhihu.com/?target=http%3A//www.wuli.ac.cn/CN/abstract/abstract69822.shtml' rel='nofollow noreferrer' target='_blank'>\n  量子物理推动机器学习\n </a>\n <br/>\n</p>\n<p>\n <b>\n  Maria Schuld 讲述了研究人员正如何通过与量子计算结合增强机器学习（一种使计算机可以学习和预测的方法）。\n </b>\n</p>\n<p>\n 蓝色房间中人们都全神关注。在正中间的桌子旁坐着两位棋手，注视着黑白大理石棋子，无声地下棋。\n \n最终，右边的棋手投子认输,他是围棋九段大师李世乭。坐在左边的是软件的开发者黄世杰，他从AlphaGo（由谷歌的DeepMind团队开发的程序）那里得到指示来下棋。在2016年3月的这一天，AlphaGo在五番棋中赢了四盘，打败了世界上最好的围棋选手之一。\n</p>\n<p>\n AlphaGo的成功已经被广泛认为是人工智能研究的一个里程碑。围棋比国际象棋（计算机在1997年首次赢了国际象棋世界冠军）复杂很多。在围棋中，通过蛮力搜索所有可能的策略从而找出最好的走法是行不通的；落子位置的可能组合数比宇宙中的原子还要多，而AlphaGo所使用的2200个处理器的计算能力与今天的超级计算机相比还算是轻量级的。其实，AlphaGo成功的秘密在于和一个特殊的陪练进行严格地练习，而这个陪练就是软件自己。为了成为一个称职的陪练，AlphaGo的“深度神经网络”（受人脑结构启发而来的计算机算法）最开始通过参考包含大约三千万个专业走法的数据库来掌握这个游戏。\n</p>\n<p>\n 机器学习可以被认为是人工智能侧重于数据的一面，其中要处理大量的信息或者说“大数据”。类似于人类的学习方式，机器学习涉及到把问题的海量实例输入到计算机，它利用数据的模式来解决以前从未出现过的情况。\n \n例如，喂给一个计算机许多同一个人的图片，再给它另一个新的图片问是否是同一个人。难点在于我们不知道如何将视神经的视觉刺激和在图片中认出一个人这件事联系起来。换句话说，在像素级别的描述（比如说在位置（1334，192）这个点是红色）和“照片中有我们的朋友Sivu”之间没有一个简单的关联，知道这样的关联可以指导我们如何编程。机器学习方法因此必须给出一个一般的方法来找出数据中复杂的模式，正如Facebook的自动标记功能所展示的，机器学习的这一能力在不断的提高。\n</p>\n<p>\n 物理学，或者更精确地说，量子物理学能在其中发挥什么作用呢？运行AlphaGo的计算机是基于经典物理的。处理信息的方式是通过操控0和1信号的微电子线路，而这些线路遵从经典电动力学。物理学家已经开始从头思考计算的概念有二十年了：如果我们造一个基于量子理论的计算机会怎么样？这样一个设备会从根本上改变可以计算的极限么？虽然看起来我们对这个问题已经有很多理解了，事实证明，这并不容易回答。尽管我们还没有能力去建造一个足够大的以至于能解决现实问题的量子计算机，已经有若干个强力的数学语言被发展出来用以刻画和研究“量子算法”（量子计算机的软件）了。这样的研究工作现在不只局限在纯粹的学术界，在一些大的IT公司比如谷歌和IBM也开始在这方面竞赛。随着我们越来越确信量子计算机实现的可行性，寻找量子计算机“杀手锏应用”的紧迫性也在不断增长。于是，机器学习就登场了。\n</p>\n<p>\n 既然我们知道量子计算机以后会使用的工作语言，我们已经可以开始思考量子计算将对机器学习产生什么影响了。这样一种途径被称为由量子增强的机器学习，这是量子机器学习（这一领域还考虑相反的研究途径：用经典机器学习方法来研究量子实验中产生的数据）这一更大领域的一部分。为了了解由量子增强的机器学习，我们首先要理解机器学习是怎么工作的以及其优势背后的“黑箱”。\n</p>\n<p>\n <b>\n  机器学习\n </b>\n</p>\n<p>\n 一个很快捷的去领悟机器学习概念的方法是通过考虑数据拟合，大部分科学家在本科阶段都接触过它，而且这是众多发现数据中模式和趋势的方法之一。想象你做了一个实验生成了数据点(x,y)，其中x是可控参数，y是测量结果。作为物理学家，你可能想得到一个可以解释这些测量结果的模型。换句话说，你想通过产生的数据，在一定误差下，找到关系y=f(x)。这可以通过把数据喂给计算机，然后利用数值软件找出依赖于参数的函数f(x)中拟合得最好的一个来做到（图1）。用数学的术语来说，这是一个优化问题。\n</p>\n<p>\n 对机器学习来说，解决优化问题已经做了一半的工作。在做实验前，人们可以通过最好的模型或者说拟合函数来预测新的控制参数下的测量结果。当然，对大部分的机器学习应用，人们对物理实验的兴趣小于对传统上认为需要人类经验的任务。例如，x可以表示一组宏观经济学变量而y代表了下周油价的涨幅。如果我们从数据中推出了模型y=f(x)，我们就可以用它去预测明天的油价。又或者，输入可以是照片的像素集而输出是关于你的朋友Sivu是否在照片中的回答，在这种情况下，机器学习被用来做图像识别。这些应用中的一个共同点是它们让我们可以回答关于复杂关系的问题，且答案又很值钱。\n</p>\n\n \n  <img src='https://pic1.zhimg.com/v2-d1e2ac9ac602471783470fdf17837c34_b.jpg' width='640'>\n \n \n\n<p>\n 图1：让模型尽量简单。在给定相同数据集（黑色）的情况下，曲线拟合软件给出了两个不同的模型（蓝色和红色）。尽管模型1完美地拟合了数据，但是弯曲度更小的模型2有更好的泛化能力，于是对新数据有更好的预测。（图中的单词：数据、模型1、模型2、新数据、模型1的预测、模型2的预测）\n</p>\n<p>\n 至此，这些听起来都很直接。你所要做的就是解决一个优化问题从而找到最好的预测模型。但是机器学习通常处理的那类优化问题非常困难，以至于一些富于挑战精神的数学家也会避开它们。比如说，想一想一个优化问题的地形像喜马拉雅山那么大，而你要靠双脚并在没有地图的情况下找到最深的山谷（图2）。而且，真正的“黑箱”在于表述优化问题的微妙性。比如说，在图1数据拟合的例子中，如果我们定义最好的模型为，对所有数据点y来说，离它们最近的f(x)，更弯曲的函数（蓝色）更好，因为这个模型函数穿过了所有的数据点。但当我们引入一个新的数据点，很清楚地看到，更粗糙的拟合（红色）给出了更好的预测。对于我们的登山者来说，弯曲程度更高的模型所对应的优化问题的地形不是太有用，因为即使我们找到了最深的山谷，这并不意味着一个好的模型。一个有用的优化地形对应于最优的模型使得可以从已有数据背后的模式中泛化出还没有出现的数据，即使这并不意味着在已有数据上拟合的比较完美。给出一个有效的优化问题需要大量的直觉和实践经验，这是利用机器学习能力的关键。\n</p>\n<p>\n \n  \n   <img src='https://pic1.zhimg.com/v2-d6d92a0d254de1795171e6f8375a4010_b.jpg' width='640'>\n  \n  \n \n 图2：最优路径。一个数学上的优化问题就像一个登山者徒步在大山中寻找最深的山谷。机器学习通常需要求解复杂的优化问题，其中登山者不得不穿过非常多的山谷来找最深的那一个。\n</p>\n<p>\n <b>\n  量子推动\n </b>\n</p>\n<p>\n 用量子计算增强机器学习最常用的方法是把困难的优化问题交给量子计算机，可以是今天实验室中的小型设备，也可以是未来我们想实现的成熟版本的量子计算机。整个算法“工具箱”已经被量子信息界发展起来了。仍在持续的挑战是去组合、调整和扩展这些工具以至于对传统计算机实现压倒性优势。在方框中，更详细地解释了三个用量子计算机解优化问题的方法。虽然我们现在知道即使利用了量子效应，最困难的计算问题常常还是困难的，但是适当的加速对于今天的大数据应用来说还是至关重要的。\n</p>\n<p>\n 在把子任务交给量子计算时，有一点要特别注意。为了让这些方法能工作，需要把描述优化问题地形的数据编码到量子系统中。如图3所示，一个方法是把黑白图像表示成有指向上下自旋的格点。用量子叠加（量子系统可以同时处在两个或多个状态）允许我们将很多图片存在一个量子系统中。其他的编码策略更复杂，但全部都需要我们制备量子系统的初态来表示数据集的数值。制备一个物理系统，用于编码来自图像数据集的数以亿计的像素，并达到比较高的精度，这对一个实验物理学家来说简直就是噩梦。对于机器学习量子算法来说，编码数据是一个至关重要的瓶颈和挑战，而这没有经典计算的直接对应物。\n</p>\n\n \n  <img src='https://pic4.zhimg.com/v2-9647156a8a96eebd9f0772763c8823a7_b.jpg' width='640'>\n \n \n\n<p>\n 图3：把数据编码到量子计算机中。第一步就是把一个问题从传统计算机翻译到量子计算机，将数据编码到量子系统。在此展示的一个方法是把二进制比特表示为格点上的自旋指向上（白格子）和下（黑格子）。\n</p>\n<p>\n <b>\n  向量子AlphaGo迈进\n </b>\n</p>\n<p>\n 毫无疑问，在下一代的AlphaGo以及它的同伴能在量子硬件上运行之前，还有很长的路要走。首先，我们需要稳定的大尺度量子计算机去运行发展出来的软件。我们需要在经典数据和量子系统之间设计一个界面，使得把问题编码到设备中。我们还需要更好的量子工具来做优化，尤其是在地形复杂的情况下。\n</p>\n<p>\n 最重要的是，我们需要去学习已经经过数十年实践检验的机器学习中的“黑箱”。从现在开始，我们需要将问题表述为适合量子计算的形式而不是仅仅将经典计算中的优化问题交给量子计算机而已。一个早期的量子计算机正等着在实验室里处理一些实用问题。问题是，这些设备可以解决什么类型的优化问题，并且对于这个问题的回答是否可以用来定义新的机器学习方法？是否存在一些特定的物理学研究中的问题适合由量子增强的机器学习来处理？我们是否能用真正的“量子模型”来处理这些任务？并且我们在量子计算中的思考方式能否相对传统的机器学习研究思路有所创新？\n</p>\n<p>\n 总结一下，量子增强的机器学习这一新兴学科必须重新放在量子计算的研究框架中，并且成为一个真正的交叉学科课题。这需要在沟通和“翻译”两个领域上付出相当多的努力。然而，两边所用的语言或许没有我们想的相距遥远：量子理论和机器学习都处理观测量的统计。可能我们起初就不需要通过0/1比特这种描述。总而言之，我们还不知道在未来几十年，量子计算机能否计算AlphaGo的每步落子的决策。但是问这些问题可以让我们思考很多事情。\n</p>\n<p>\n <b>\n  方框： 实现由量子增强的机器学习的途径\n </b>\n</p>\n<p>\n <b>\n  量子搜索：\n </b>\n</p>\n<p>\n 在九十年代中期，计算机科学家Lov\n \nGrover发现用量子计算在无序数据库（比如电话号码簿）上做搜索会比经典计算机快。这一方法可以被调整为找k个最近的搜索项，或者说与给定号码有最多的共同数字（只与相同位置的比较）的k个电话号码。在机器学习中，给定输入找最近的数据点是一个很重要的任务，例如一个被叫做“k近邻”的方法就是根据近邻的y值（标记类别）去选择一个新的y值。可能最直接的用量子计算机解决机器学习问题的途径就是把搜索问题重新表述为量子计算的语言，然后应用Grover算法。\n</p>\n<p>\n <b>\n  线性代数：\n </b>\n</p>\n<p>\n 一个小的量子系统可以有大量的不同构型或者测量结果。量子理论描述了这些不同构型被测量到的概率，而这其中的数学又在很大程度上基于线性代数。在2009年，来自麻省理工学院的Aram\n Harrow, Avinatan Hassidim 和 Seth \nLloyd，聪明地利用这一特点提出了一个量子算法去解线性方程组，并且在特定情况下，这一算法快的不可思议。同样地，许多机器学习中的优化问题在数学上也被表述为解线性方程，其中的未知数个数依赖于数据集的大小。对于大数据应用来说，数值解需要消耗大量的计算资源，而这就成为量子线性方程算法绝佳的潜在应用对象。\n</p>\n<p>\n <b>\n  寻找基态：\n  <br/>\n </b>\n</p>\n第三类优化问题是去找一个比特序列去最小化一个能量函数。一个流行的数值方法是通过所谓的“模拟退火”。这个方法模拟了系统冷却到基态的热力学过程。在这一过程的量子版本中，即“量子退火”，能量地形被类似地最小化，然而这一算法可以利用量子隧穿效应越过能量尖峰，而非通过“爬坡”越过，这意味着可以更快地找到最低的山谷。量子退火设备已经存在了，即是由加拿大公司D-wave在2010年宣称的世界上第一台商用量子计算机。这些设备已经被证明（毫无疑问，这非常奇异），在寻找全局最小值的问题上，比传统计算机上运行的模拟退火算法快一亿倍。\n",
    "updateTime": "2017-03-10 00:00:00"
}